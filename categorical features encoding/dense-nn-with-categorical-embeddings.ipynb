{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dense NN with Categorical Embeddings\n",
    "\n",
    "In this notebook, we are fitting a dense neural network (based on a multilayer-perceptron / MLP) using a pre-prepared training dataset from the Predict Future Sales competition.\n",
    "\n",
    "One of the major challenges when fitting the dataset to an MLP-type Neural Network is deciding what to do with any categorical features. The discussion and approach below represents one of the possible answers to this problem.\n",
    "\n",
    "Some very basic familiarity with the concepts of multilayer-perceptrons (MLPs) and Keras are assumed - the following are really useful resources should one wish to brush up:\n",
    "\n",
    "\n",
    "<ul>\n",
    "    <li><a href=\"https://towardsdatascience.com/what-the-hell-is-perceptron-626217814f53\">What the hell is Perceptron</a></li>\n",
    "    <li><a href=\"https://www.kindsonthegenius.com/blog/2018/01/basics-of-multilayer-perceptron-a-simple-explanation-of-multilayer-perceptron.html\">Basics of Multilayer Perceptron</a></li>\n",
    "    <li><a href=\"https://keras.io/getting-started/functional-api-guide/\">Keras - Guide to the Functional API</a></li>\n",
    "</ul>\n",
    "\n",
    "Also, credit to the following excellent articles and their authors, who provided learning and inspiration for this notebook:\n",
    "\n",
    "<ul>\n",
    "    <li><a href=\"https://towardsdatascience.com/decoded-entity-embeddings-of-categorical-variables-in-neural-networks-1d2468311635\">Entity Embeddings of Categorical Variables in Neural Networks</a></li>\n",
    "    <li><a href=\"https://towardsdatascience.com/an-overview-of-categorical-input-handling-for-neural-networks-c172ba552dee\">An Overview of Categorical Input Handling for Neural Networks</a></li>\n",
    "    <li><a href=\"https://medium.com/@satnalikamayank12/on-learning-embeddings-for-categorical-data-using-keras-165ff2773fc9\">On learning embeddings for categorical data using Keras</a></li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/input/competitive-data-science-predict-future-sales/items.csv\n",
      "/kaggle/input/competitive-data-science-predict-future-sales/shops.csv\n",
      "/kaggle/input/competitive-data-science-predict-future-sales/sales_train.csv\n",
      "/kaggle/input/competitive-data-science-predict-future-sales/test.csv\n",
      "/kaggle/input/competitive-data-science-predict-future-sales/sample_submission.csv\n",
      "/kaggle/input/competitive-data-science-predict-future-sales/item_categories.csv\n",
      "/kaggle/input/nn-data/test_data_nn.pkl\n",
      "/kaggle/input/nn-data/train_data_nn.pkl\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load in \n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import regularizers\n",
    "from tensorflow.keras.layers import Concatenate, Dense, Dropout, Embedding, Input, Reshape\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "pd.options.display.float_format = '{:.4f}'.format\n",
    "# Input data files are available in the \"../input/\" directory.\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# Any results you write to the current directory are saved as output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2349928 entries, 0 to 2349927\n",
      "Data columns (total 29 columns):\n",
      "date_block_num                     float16\n",
      "item_id                            float16\n",
      "shop_id                            float16\n",
      "item_category_id                   float16\n",
      "months_since_item_first_sale       float16\n",
      "months_since_last_sale             float16\n",
      "month                              float16\n",
      "month_length                       float16\n",
      "lag_1m_cum_item/shop_sales         float32\n",
      "lag_6m_cum_item/shop_sales         float32\n",
      "lag_12m_cum_item/shop_sales        float32\n",
      "lag_1m_mean_item_sales             float32\n",
      "lag_6m_mean_item_sales             float32\n",
      "lag_12m_mean_item_sales            float32\n",
      "lag_3m_mean_shop_sales             float32\n",
      "lag_6m_mean_shop_sales             float32\n",
      "lag_12m_mean_shop_sales            float32\n",
      "lag_1m_mean_shop_cat/item_sales    float32\n",
      "lag_1m_mean_cat/shop_sales         float32\n",
      "lag_3m_mean_cat/shop_sales         float32\n",
      "lag_6m_mean_cat/shop_sales         float32\n",
      "lag_9m_mean_cat/shop_sales         float32\n",
      "lag_12m_mean_cat/shop_sales        float32\n",
      "lag_3m_mean_cat_revenue            float32\n",
      "lag_6m_mean_cat_revenue            float32\n",
      "lag_1m_mean_sales                  float32\n",
      "lag_12m_mean_sales                 float32\n",
      "item_cnt_month                     int8\n",
      "ID                                 int64\n",
      "dtypes: float16(8), float32(19), int64(1), int8(1)\n",
      "memory usage: 226.3 MB\n"
     ]
    }
   ],
   "source": [
    "train_data = pd.read_pickle('../input/nn-data/train_data_nn.pkl')\n",
    "test_data = pd.read_pickle('../input/nn-data/test_data_nn.pkl')\n",
    "train_data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The Theory\n",
    "\n",
    "<h2>General Data Types <small>(statistical data types that is....)</small> </h2>\n",
    "\n",
    "Above, you can see the training dataset contains many examples (approx 3.75M) and has a relatively large number of features (29 including ID and target variable). The features include examples of each of the main types of statistical data:\n",
    "\n",
    "<h4>Numerical:</h4>\n",
    "\n",
    " * <span style=\"color:darkblue\">Discrete</span> - countable features that take only integer values, such as <code>month_length</code> or  <code>months_since_last_sale</code>\n",
    " * <span style=\"color:darkblue\">Continuous</span> - measurable features that take a range of values and are measured / calculated rather than counted, for example <code>lag_1m_mean_sales</code> or <code>lag_3m_mean_cat_revenue</code>\n",
    "\n",
    "<h4>Categorical:</h4>\n",
    "\n",
    " * <span style=\"color:darkblue\">Nominal</span> - features that can't be represented numerically, other than to give them an arbitrary ID that has no numerical meaning. Examples are (pretty obviously anything suffixed with id) <code>item_id</code> or  <code>item_category_id</code>\n",
    " * <span style=\"color:darkblue\">Ordinal</span> - discrete features that can be ordered, but are still categorical or can't be explained by counting only. A simple example would be education level (primary / secondary / university). Whilst debatable, it can be argued that <code>month</code> is an ordinal feature (particularly as it's distinguished from <code>date_block_num</code>). In this setting (retail sales), the different months have a significance beyond their numerical position in the year (given the holidays they contain for example), and so can't be explained by just counting them up and numbering them.\n",
    " \n",
    "<h2>MLP Challenges</h2>\n",
    "\n",
    "The categorical features in the dataset present a problem for a multilayer perceptron (MLP). Each node or \"perceptron\" in an MLP is activated based on the linear combination of the node's inputs multiplied by the (trainable) weights corresponding to each input, very similar in spirit to linear regression:\n",
    "\n",
    "<br>\n",
    "\n",
    "![IMG-20191206-163546.jpg](https://i.postimg.cc/T1DNBfb1/IMG-20191206-163546.jpg)\n",
    "\n",
    "<br>\n",
    "\n",
    "This presents two obvious problems where categorical data is concerned:\n",
    "1. The model is simply unable to handle non-numerical input. So all categorical data must be converted into numerical data.\n",
    "2. The categorical data should be **interpretable** by the model as numerical data.\n",
    "\n",
    "As such, it's not good enough simply to convert your categories into an ordinal variable (i.e. an ID) and feed that into the MLP. The structure will assume a numeric relationship between all the inputs, and so **id 4** would be assumed to have a magnitude that is twice that of **id 2** which is, of course, nonsense.\n",
    "\n",
    "<h2>The Traditional Solution</h2>\n",
    "\n",
    "The traditional work-around for this issue is to use <bold>One Hot Encoding</bold>. This simply involves creating a new feature for each different category within your categorical feature, and assigning the new features the values 1 if they match the category and 0 if they don't. For example, from the following data:\n",
    "\n",
    "<br>\n",
    "\n",
    "<table>\n",
    "  <tr>\n",
    "    <th>name:</th>\n",
    "    <th>animal</th>\n",
    "    <th>age</th>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>Fido</td>\n",
    "    <td>Dog</td>\n",
    "    <td>10</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>Spanky</td>\n",
    "    <td>Cat</td>\n",
    "    <td>8</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>Nibbles</td>\n",
    "    <td>Rabbit</td>\n",
    "    <td>2.5</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>Jaws</td>\n",
    "    <td>Dog</td>\n",
    "    <td>4</td>\n",
    "  </tr>\n",
    "</table>\n",
    "\n",
    "<br>\n",
    "\n",
    "<text>.... the animal category could be converted via One Hot Encoding to:</text>\n",
    "\n",
    "<br>\n",
    "\n",
    "<table>\n",
    "  <tr>\n",
    "    <th>name:</th>\n",
    "    <th>age</th>\n",
    "    <th>Dog</th>\n",
    "    <th>Cat</th>\n",
    "    <th>Rabbit</th>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>Fido</td>\n",
    "    <td>10</td>\n",
    "    <td>1</td>\n",
    "    <td>0</td>\n",
    "    <td>0</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>Spanky</td>\n",
    "    <td>8</td>\n",
    "    <td>0</td>\n",
    "    <td>1</td>\n",
    "    <td>0</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>Nibbles</td>\n",
    "    <td>2.5</td>\n",
    "    <td>0</td>\n",
    "    <td>0</td>\n",
    "    <td>1</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>Jaws</td>\n",
    "    <td>4</td>\n",
    "    <td>1</td>\n",
    "    <td>0</td>\n",
    "    <td>0</td>\n",
    "  </tr>\n",
    "</table>\n",
    "\n",
    "<br>\n",
    "\n",
    "Simple! This approach does come with a couple of key drawbacks however:\n",
    "\n",
    "1. When presented with a feature with several elements / several categorical features / both, it doesn't take long for your dataset to reach unmanageably large dimensions\n",
    "2. Often categorical features are interrelated. One Hot Encoding treats all categories as independent of one another. Take for example the days of the week - Monday-Friday and Saturday/Sunday have particular shared relationships not captured by simply encoding them in separate features\n",
    "\n",
    "The dimensionality issue is particularly stark in this case, as our dataset is already ~2.5M examples by 25+ features, 5 of which are purely categorical. Within these 5 categorical features are tens of thousands of individual distinct elements, and so it's simply not feasible to consider One Hot Encoding in this case (without dropping some of the categorical features outright).\n",
    "\n",
    "Thankfully, there is a solution that addresses all of these issues:\n",
    "\n",
    "<h2>Embedding Categorical Features</h2>\n",
    "\n",
    "If you've read anything about natural language processing, you will certainly have encountered the concept of embeddings before. An embedding is an encoding of the properties of categorical information in a fixed-length numerical form. This is particularly useful in natural language processing as the meaning and semantics of a word or sentence can be represented numerically in a fixed-length vector.\n",
    "\n",
    "An example could be an embedding of the words **King, Prince, Queen, Princess** as follows:\n",
    "\n",
    "<div style=\"text-align:center\"><code>King = [-1,1]</code></div>\n",
    "<div style=\"text-align:center\"><code>Prince = [-1,-1]</code></div>\n",
    "<div style=\"text-align:center\"><code>Queen = [1,1]</code></div>\n",
    "<div style=\"text-align:center\"><code>Princess = [1,-1]</code></div>\n",
    "\n",
    "<br>\n",
    "\n",
    "In this example, the first dimension encodes the **masculinity / femininity** of the word, and the second dimension the age attribute **young / old**. Of course, in reality much longer vectors are used and in such a way that it's not so easy to distinguish definite features.\n",
    "\n",
    "This concept can be leveraged to interpret categorical data to be fed to an MLP. Embedding layers can be added for any categorical features in the dataset, which convert the data into a vector that is fed into the MLP input layer. The embedding layer itself is trainable as part of the neural network, and so learns the 'meaning' of the different categorical data as it trains.\n",
    "\n",
    "<h2>Embedding Layer</h2>\n",
    "\n",
    "An embedding layer is pretty simple. It can be thought of as a lookup table of weights that has the same number of rows as your output embedding vector, and the same number of columns as there are categories in your categorical feature. For example, if you had 10 different elements in your categorical feature, you could visualise your embedding layer like so:\n",
    "\n",
    "<br>\n",
    "\n",
    "![IMG-20191206-163111.jpg](https://i.postimg.cc/wMFbc7cK/IMG-20191206-163111.jpg)\n",
    "\n",
    "<br>\n",
    "\n",
    "This embedding layer would convert each sample in your categorical feature into a vector of length 5. As it trains, your network will then update the weights in the table to best \"describe\" each element of your categorical feature.\n",
    "\n",
    "<h2>Adding Embedding Layers to an MLP</h2>\n",
    "\n",
    "Embedding layers like the above can be added for each of the categorical features in your dataset. The values from the vector outputs of these embeddings can then be fed into a basic MLP alongside the numeric data in your dataset, which is fed straight into the MLP unchanged:\n",
    "\n",
    "<br>\n",
    "\n",
    "![IMG-20191206-164746.jpg](https://i.postimg.cc/NfbRYZxj/IMG-20191206-164746.jpg)\n",
    "\n",
    "<br>\n",
    "\n",
    "The whole network is then trained in forward / backward passes that begin and end at the embedding layers. By training the embedding layers, the network can learn the best embedding that represents the different features of the categorical variables.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basic Keras Example\n",
    "\n",
    "Now let's get down to some business. You can pretty easily build a basic Neural Network with categorical feature embeddings using Keras. A simple example for a dataset with one categorical feature and 9 numerical features might look like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_basic_model():\n",
    "    # Specify the number of different elements in the categorical feature and \n",
    "    # the length of the embedding vector these elements are going to be converted to.\n",
    "    # This information is required when defining an embedding layer.\n",
    "    elements_in_category = 10\n",
    "    embedding_size = int(min(elements_in_category / 2, 50))\n",
    "\n",
    "    # create an input for the categorical feature\n",
    "    categorical_input = Input(shape=(1,))\n",
    "    \n",
    "    # create an input for the remaining numerical data\n",
    "    numerical_input = Input(shape=(9,))    \n",
    "    \n",
    "    # crate an embedding layer for the categorical feature\n",
    "    category_embedding = Embedding(elements_in_category, \n",
    "                                   embedding_size, \n",
    "                                   input_length=1)(categorical_input)\n",
    "    category_embedding = Reshape(target_shape=(embedding_size,))(category_embedding)\n",
    "\n",
    "    # concatenate the embedding values from the categorical input \n",
    "    # and the numerical inputs together\n",
    "    inputs = Concatenate(axis=-1)([category_embedding, numerical_input])\n",
    "\n",
    "    # create a basic 100 node MLP with a single node regression output\n",
    "    dense_layer = Dense(100, activation='relu', \n",
    "                        kernel_regularizer=regularizers.l2(0.01))(inputs)\n",
    "    output_layer = Dense(1, kernel_regularizer=regularizers.l2(0.01))(dense_layer)   \n",
    "\n",
    "    # build the model\n",
    "    model = keras.Model(inputs=[categorical_input, numerical_input], outputs=output_layer)\n",
    "    optimizer = tf.keras.optimizers.Adam(learning_rate=0.01)\n",
    "    model.compile(loss='mse',\n",
    "                  optimizer=optimizer,\n",
    "                  metrics=['mae', 'mse'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<small><i><b>Note:</b> the model has to be defined using Keras' <a href=\"https://keras.io/getting-started/functional-api-guide/\">Functional / Model class API</a>, rather than the more streamlined <a href=\"https://keras.io/getting-started/sequential-model-guide/\">sequential model API</a> that some folk are more familiar with. This is simply because when using the sequential model, any layers added to the model are applied universally to the outputs of all preceding layers. It's not possible to apply an embedding layer to a selection of the input data using the sequential model - either you embed all your input data or none at all</i></small>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building a Model to Fit the Predict Future Sales Data\n",
    "\n",
    "Now that we've seen a basic example we can create a model for the competition data. The training/test data used in this notebook has already been prepared beforehand with a number of engineered features, and has been scaled and shuffled to speed up the neural network training process. A bit of work is needed to create a dataset that the embedding model will be happy with.\n",
    "\n",
    "<h2>Data Preparation</h2>\n",
    "\n",
    "Firstly, the categorical features will need to be identified and given ordinal encodings for each individual element in each category (i.e. encoding each element with a number from 0 to the total number of elements):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "\n",
    "cat_features = ['date_block_num', 'item_id', 'shop_id', 'item_category_id', 'months_since_item_first_sale',\n",
    "                'months_since_last_sale', 'month', 'month_length']\n",
    "\n",
    "train_test_cat_features = pd.concat([train_data[cat_features], test_data[cat_features]])\n",
    "\n",
    "enc = OrdinalEncoder().fit(train_test_cat_features)\n",
    "\n",
    "train_data_cat_features = pd.DataFrame(enc.transform(train_data[cat_features]),\n",
    "                                       columns=cat_features)\n",
    "test_data_cat_features = pd.DataFrame(enc.transform(test_data[cat_features]),\n",
    "                                      columns=cat_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An important point to note: some of the features chosen might be thought of as traditional discrete numerical data, such as <code>months_since_item_first_sale</code>. Whilst this may be so, often values within these discrete features are not entirely independent of one another and can include some element of covariability, as more traditional categorical features might.\n",
    "\n",
    "An example might be a particular period after an item is first sold, when items are typically reduced as a promotion - the months preceding / after the promotion period will be more closely associated with one another. By embedding these features, we can capture these additional associations if there are any (as they will then be represented by a vector of continuous values rather than an individual discrete value), at no loss (other than additional complexity) if they are indeed completely independent.\n",
    "\n",
    "As a general rule of thumb, any discrete feature that has a relatively small range of values may well benefit from encoding, and so it's worth treating all such features as categorical in this setting.\n",
    "\n",
    "All categorical features will then need to be fed into the model separately. The model accepts a list of inputs: an individual integer for each categorical feature, and a vector of the remaining numerical data. For example, a training example containing three categorical features and five numeric features might look like this:\n",
    "\n",
    "<div style=\"text-align:center\"><code><b>[5],[41],[3],[-0.6,1.1,0.1,-1.2,-0.8]</b></code></div>\n",
    "\n",
    "<br>\n",
    "\n",
    "Of course, the prepared dataset will contain multiple training examples - a vector for each categorical feature with a length equal to the number of training examples, and a matrix for the numerical data with dimensions (number of examples x number of numeric features):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we will be using the last month of training data as a validation set to train the NN\n",
    "val_mask = train_data_cat_features.date_block_num == (train_data_cat_features.date_block_num.max())\n",
    "\n",
    "# Features that aren't to be included in the training data\n",
    "# 'item_cnt_month' is the target and ID is not a descriptive feature\n",
    "drop_features = ['item_cnt_month', 'ID']\n",
    "\n",
    "# inputs to model need to come in the form of a list containing a (1,n) vector\n",
    "# for each categorical variable in order, and a (n, n_continuous_features) matrix\n",
    "# of the remaining continuous features\n",
    "X_train = []\n",
    "\n",
    "# this loops over the categorical features and creates an individual vector for\n",
    "# each one, appending it to the input list\n",
    "for cat in cat_features:\n",
    "  X_train.append(np.array(train_data_cat_features[~val_mask][cat]).reshape(-1,1))\n",
    "\n",
    "# the remaining continuous features are appended to the end of the list as a matrix\n",
    "X_train.append(train_data[~val_mask].drop(drop_features + cat_features, axis=1).values)\n",
    "y_train = train_data[~val_mask].item_cnt_month\n",
    "\n",
    "X_val = []\n",
    "\n",
    "for cat in cat_features:\n",
    "  X_val.append(np.array(train_data_cat_features[val_mask][cat]).reshape(-1,1))\n",
    "\n",
    "X_val.append(train_data[val_mask].drop(drop_features + cat_features, axis=1).values)\n",
    "y_val = train_data[val_mask].item_cnt_month\n",
    "\n",
    "X_test=[]\n",
    "\n",
    "for cat in cat_features:\n",
    "    X_test.append(np.array(test_data_cat_features[cat]).reshape(-1,1))\n",
    "\n",
    "X_test.append(test_data.drop(cat_features, axis=1).values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following is an example of the first couple of data points in the training dataset (a tad messy looking but you get the idea):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[0.],\n",
       "        [1.]]), array([[2829.],\n",
       "        [ 576.]]), array([[30.],\n",
       "        [24.]]), array([[28.],\n",
       "        [16.]]), array([[23.],\n",
       "        [ 2.]]), array([[5.],\n",
       "        [0.]]), array([[11.],\n",
       "        [ 0.]]), array([[2.],\n",
       "        [2.]]), array([[ 0.        ,  0.        ,  0.        , -0.3333333 , -0.3837209 ,\n",
       "         -0.3503185 , -0.49076572, -0.8107233 , -1.0361814 , -0.14814815,\n",
       "         -0.26341057, -0.23555253, -0.2991169 , -0.31922275, -0.32580206,\n",
       "         -0.02474844, -0.05221799,  0.38018858,  0.318096  ],\n",
       "        [ 5.        ,  7.        ,  3.5       ,  5.8666663 ,  0.74418604,\n",
       "          0.23566876,  2.969811  ,  2.6643963 ,  2.5122256 ,  6.962963  ,\n",
       "          8.345599  ,  4.1375403 ,  2.2738938 ,  1.3659759 ,  0.93930066,\n",
       "          6.5508337 ,  3.460384  ,  1.3085648 ,  0.25620696]],\n",
       "       dtype=float32)]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_examples_2 = []\n",
    "for data in X_train:\n",
    "  train_examples_2.append(data[:2])\n",
    "\n",
    "train_examples_2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Building the Model</h2>\n",
    "\n",
    "With the data prepared we can now move onto the model. \n",
    "\n",
    "First, a function is defined to create the categorical embedding layers. The function accepts as input a list of the categorical feature names. Each embedding is given a length half that of the number of elements in a category, or of 50, whichever is lower. Each input and embedding layer is then saved in a dict that can be referred to when defining the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prevents any conflicts with previously loaded models\n",
    "tf.keras.backend.clear_session() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_categorical_inputs(features):\n",
    "\n",
    "    initial_inputs = {}\n",
    "    cat_input_layers={}\n",
    "\n",
    "    for feature in features:\n",
    "        no_of_unique_cats  = train_test_cat_features[feature].nunique()\n",
    "        embedding_size = int(min(np.ceil((no_of_unique_cats)/2), 50))\n",
    "        categories  = no_of_unique_cats + 1\n",
    "\n",
    "        initial_inputs[feature] = Input(shape=(1,))\n",
    "        embedding_layer = Embedding(categories, \n",
    "                                    embedding_size,\n",
    "                                    embeddings_regularizer=regularizers.l2(0.01),\n",
    "                                    input_length=1)(initial_inputs[feature])\n",
    "        cat_input_layers[feature] = Reshape(target_shape=(embedding_size,))(embedding_layer)\n",
    "\n",
    "    return initial_inputs, cat_input_layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The rest of the model can then be created. Structured in the same way as the basic model example, this model simply leverages the above function to create several categorical embeddings, and features a number of hidden layers to capture more information from the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model():\n",
    "  \n",
    "    initial_inputs, input_layers = build_categorical_inputs(cat_features)\n",
    "\n",
    "    no_of_num_features = len(train_data.columns) - len(cat_features) - len(drop_features)\n",
    "    \n",
    "    initial_inputs['numerical_features'] = Input(shape=(no_of_num_features,))\n",
    "    input_layers['numerical_features'] = initial_inputs['numerical_features']\n",
    "\n",
    "    inputs = Concatenate(axis=-1)([layer for layer in input_layers.values()])\n",
    "\n",
    "    drop_1_out = Dropout(0.1)(inputs)\n",
    "    dense_1_out = Dense(256, activation='relu', \n",
    "                        kernel_regularizer=regularizers.l2(0.01))(drop_1_out)\n",
    "    drop_2_out = Dropout(0.1)(dense_1_out)\n",
    "    dense_2_out = Dense(125, activation='relu', \n",
    "                        kernel_regularizer=regularizers.l2(0.01))(drop_2_out)\n",
    "    drop_3_out = Dropout(0.1)(dense_2_out)\n",
    "    dense_3_out = Dense(64, activation='relu', \n",
    "                        kernel_regularizer=regularizers.l2(0.01))(drop_3_out)\n",
    "    drop_4_out = Dropout(0.1)(dense_3_out)\n",
    "    dense_4_out = Dense(32, activation='relu', \n",
    "                        kernel_regularizer=regularizers.l2(0.01))(drop_4_out)\n",
    "    final_out = Dense(1, kernel_regularizer=regularizers.l2(0.01))(dense_4_out)   \n",
    "\n",
    "    model = keras.Model(inputs=[input for input in initial_inputs.values()], \n",
    "                        outputs=final_out)\n",
    "\n",
    "    optimizer = tf.keras.optimizers.Adam(learning_rate=0.00001)\n",
    "\n",
    "    model.compile(loss='mse',\n",
    "                  optimizer=optimizer,\n",
    "                  metrics=['mae', 'mse'])\n",
    "    \n",
    "    return model\n",
    "\n",
    "model = build_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following summary describes the features of the model layer by layer. Note the trainable parameters for each categorical feature, which total the length of the output embedding multiplied by the number of elements in the category:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_3 (InputLayer)            [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_4 (InputLayer)            [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_5 (InputLayer)            [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_6 (InputLayer)            [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_7 (InputLayer)            [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_8 (InputLayer)            [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding (Embedding)           (None, 1, 6)         78          input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "embedding_1 (Embedding)         (None, 1, 50)        169950      input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "embedding_2 (Embedding)         (None, 1, 28)        1596        input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "embedding_3 (Embedding)         (None, 1, 31)        1953        input_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "embedding_4 (Embedding)         (None, 1, 18)        648         input_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "embedding_5 (Embedding)         (None, 1, 17)        578         input_6[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "embedding_6 (Embedding)         (None, 1, 6)         78          input_7[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "embedding_7 (Embedding)         (None, 1, 2)         8           input_8[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "reshape (Reshape)               (None, 6)            0           embedding[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "reshape_1 (Reshape)             (None, 50)           0           embedding_1[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "reshape_2 (Reshape)             (None, 28)           0           embedding_2[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "reshape_3 (Reshape)             (None, 31)           0           embedding_3[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "reshape_4 (Reshape)             (None, 18)           0           embedding_4[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "reshape_5 (Reshape)             (None, 17)           0           embedding_5[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "reshape_6 (Reshape)             (None, 6)            0           embedding_6[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "reshape_7 (Reshape)             (None, 2)            0           embedding_7[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "input_9 (InputLayer)            [(None, 19)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 177)          0           reshape[0][0]                    \n",
      "                                                                 reshape_1[0][0]                  \n",
      "                                                                 reshape_2[0][0]                  \n",
      "                                                                 reshape_3[0][0]                  \n",
      "                                                                 reshape_4[0][0]                  \n",
      "                                                                 reshape_5[0][0]                  \n",
      "                                                                 reshape_6[0][0]                  \n",
      "                                                                 reshape_7[0][0]                  \n",
      "                                                                 input_9[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout (Dropout)               (None, 177)          0           concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 256)          45568       dropout[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 256)          0           dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 125)          32125       dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)             (None, 125)          0           dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 64)           8064        dropout_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_3 (Dropout)             (None, 64)           0           dense_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 32)           2080        dropout_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_4 (Dense)                 (None, 1)            33          dense_3[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 262,759\n",
      "Trainable params: 262,759\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As a quick sanity check, we can have the model make untrained predictions on our training examples. Any issues when preparing the data or building the model will quickly become obvious:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.01943396],\n",
       "       [ 0.2637895 ],\n",
       "       [-0.18221751],\n",
       "       [ 0.06414639],\n",
       "       [ 0.00714784],\n",
       "       [ 0.09179152],\n",
       "       [ 1.4761764 ],\n",
       "       [ 0.08349843],\n",
       "       [-0.03434511],\n",
       "       [ 0.09465382]], dtype=float32)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_examples_10 = []\n",
    "for data in X_train:\n",
    "  train_examples_10.append(data[:10])\n",
    "\n",
    "example_result = model.predict(train_examples_10)\n",
    "example_result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Thankfully it doesn't seem like there are any problems. All that remains is to train the model and output the results of training:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Training, Evaluation and Prediction\n",
    "\n",
    "The rest of the process should speak for itself...."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 2084656 samples, validate on 265272 samples\n",
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/tensorflow_core/python/framework/indexed_slices.py:433: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
      "/opt/conda/lib/python3.6/site-packages/tensorflow_core/python/framework/indexed_slices.py:433: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2083000/2084656 [============================>.] - ETA: 0s - loss: 6.4641 - mae: 0.3560 - mse: 1.1487\n",
      "Epoch 00001: saving model to /kaggle/working\n",
      "2084656/2084656 [==============================] - 39s 19us/sample - loss: 6.4637 - mae: 0.3560 - mse: 1.1491 - val_loss: 5.2589 - val_mae: 0.2846 - val_mse: 0.8577\n",
      "Epoch 2/30\n",
      "2084000/2084656 [============================>.] - ETA: 0s - loss: 4.8442 - mae: 0.3584 - mse: 1.0156\n",
      "Epoch 00002: saving model to /kaggle/working\n",
      "2084656/2084656 [==============================] - 37s 18us/sample - loss: 4.8441 - mae: 0.3584 - mse: 1.0157 - val_loss: 4.2079 - val_mae: 0.2849 - val_mse: 0.8419\n",
      "Epoch 3/30\n",
      "2084000/2084656 [============================>.] - ETA: 0s - loss: 4.0347 - mae: 0.3550 - mse: 0.9837\n",
      "Epoch 00003: saving model to /kaggle/working\n",
      "2084656/2084656 [==============================] - 38s 18us/sample - loss: 4.0348 - mae: 0.3550 - mse: 0.9839 - val_loss: 3.6229 - val_mae: 0.2744 - val_mse: 0.8385\n",
      "Epoch 4/30\n",
      "2082000/2084656 [============================>.] - ETA: 0s - loss: 3.5526 - mae: 0.3517 - mse: 0.9667\n",
      "Epoch 00004: saving model to /kaggle/working\n",
      "2084656/2084656 [==============================] - 37s 18us/sample - loss: 3.5521 - mae: 0.3516 - mse: 0.9664 - val_loss: 3.2425 - val_mae: 0.2670 - val_mse: 0.8320\n",
      "Epoch 5/30\n",
      "2084000/2084656 [============================>.] - ETA: 0s - loss: 3.2290 - mae: 0.3470 - mse: 0.9558\n",
      "Epoch 00005: saving model to /kaggle/working\n",
      "2084656/2084656 [==============================] - 37s 18us/sample - loss: 3.2288 - mae: 0.3470 - mse: 0.9556 - val_loss: 2.9769 - val_mae: 0.2667 - val_mse: 0.8275\n",
      "Epoch 6/30\n",
      "2082000/2084656 [============================>.] - ETA: 0s - loss: 2.9845 - mae: 0.3437 - mse: 0.9381\n",
      "Epoch 00006: saving model to /kaggle/working\n",
      "2084656/2084656 [==============================] - 38s 18us/sample - loss: 2.9846 - mae: 0.3437 - mse: 0.9384 - val_loss: 2.7750 - val_mae: 0.2641 - val_mse: 0.8233\n",
      "Epoch 7/30\n",
      "2083000/2084656 [============================>.] - ETA: 0s - loss: 2.8086 - mae: 0.3420 - mse: 0.9371\n",
      "Epoch 00007: saving model to /kaggle/working\n",
      "2084656/2084656 [==============================] - 37s 18us/sample - loss: 2.8085 - mae: 0.3420 - mse: 0.9371 - val_loss: 2.6163 - val_mae: 0.2665 - val_mse: 0.8217\n",
      "Epoch 8/30\n",
      "2084000/2084656 [============================>.] - ETA: 0s - loss: 2.6497 - mae: 0.3404 - mse: 0.9272\n",
      "Epoch 00008: saving model to /kaggle/working\n",
      "2084656/2084656 [==============================] - 37s 18us/sample - loss: 2.6496 - mae: 0.3404 - mse: 0.9271 - val_loss: 2.4717 - val_mae: 0.2647 - val_mse: 0.8196\n",
      "Epoch 9/30\n",
      "2084000/2084656 [============================>.] - ETA: 0s - loss: 2.0596 - mae: 0.3344 - mse: 0.9043\n",
      "Epoch 00013: saving model to /kaggle/working\n",
      "2084656/2084656 [==============================] - 39s 19us/sample - loss: 2.0594 - mae: 0.3344 - mse: 0.9042 - val_loss: 1.9260 - val_mae: 0.2564 - val_mse: 0.8129\n",
      "Epoch 14/30\n",
      "2084000/2084656 [============================>.] - ETA: 0s - loss: 1.9751 - mae: 0.3337 - mse: 0.9023\n",
      "Epoch 00014: saving model to /kaggle/working\n",
      "2084656/2084656 [==============================] - 38s 18us/sample - loss: 1.9755 - mae: 0.3337 - mse: 0.9027 - val_loss: 1.8440 - val_mae: 0.2569 - val_mse: 0.8097\n",
      "Epoch 15/30\n",
      "2083000/2084656 [============================>.] - ETA: 0s - loss: 1.8971 - mae: 0.3331 - mse: 0.8990\n",
      "Epoch 00015: saving model to /kaggle/working\n",
      "2084656/2084656 [==============================] - 38s 18us/sample - loss: 1.8973 - mae: 0.3331 - mse: 0.8992 - val_loss: 1.7756 - val_mae: 0.2559 - val_mse: 0.8124\n",
      "Epoch 16/30\n",
      "2083000/2084656 [============================>.] - ETA: 0s - loss: 1.8288 - mae: 0.3322 - mse: 0.8978\n",
      "Epoch 00016: saving model to /kaggle/working\n",
      "2084656/2084656 [==============================] - 39s 18us/sample - loss: 1.8285 - mae: 0.3322 - mse: 0.8975 - val_loss: 1.7120 - val_mae: 0.2549 - val_mse: 0.8123\n",
      "Epoch 17/30\n",
      "2084000/2084656 [============================>.] - ETA: 0s - loss: 1.7675 - mae: 0.3320 - mse: 0.8969\n",
      "Epoch 00017: saving model to /kaggle/working\n",
      "2084656/2084656 [==============================] - 39s 19us/sample - loss: 1.7675 - mae: 0.3320 - mse: 0.8970 - val_loss: 1.6537 - val_mae: 0.2514 - val_mse: 0.8115\n",
      "Epoch 18/30\n",
      "2084000/2084656 [============================>.] - ETA: 0s - loss: 1.7058 - mae: 0.3307 - mse: 0.8904\n",
      "Epoch 00018: saving model to /kaggle/working\n",
      "2084656/2084656 [==============================] - 38s 18us/sample - loss: 1.7057 - mae: 0.3307 - mse: 0.8904 - val_loss: 1.6000 - val_mae: 0.2513 - val_mse: 0.8113\n",
      "Epoch 19/30\n",
      "2084000/2084656 [============================>.] - ETA: 0s - loss: 1.6560 - mae: 0.3302 - mse: 0.8921\n",
      "Epoch 00019: saving model to /kaggle/working\n",
      "2084656/2084656 [==============================] - 39s 19us/sample - loss: 1.6560 - mae: 0.3302 - mse: 0.8921 - val_loss: 1.5495 - val_mae: 0.2556 - val_mse: 0.8099\n",
      "Epoch 20/30\n",
      "2084000/2084656 [============================>.] - ETA: 0s - loss: 1.6097 - mae: 0.3308 - mse: 0.8924\n",
      "Epoch 00020: saving model to /kaggle/working\n",
      "2084656/2084656 [==============================] - 39s 19us/sample - loss: 1.6096 - mae: 0.3308 - mse: 0.8924 - val_loss: 1.5006 - val_mae: 0.2548 - val_mse: 0.8055\n",
      "Epoch 21/30\n",
      "2082000/2084656 [============================>.] - ETA: 0s - loss: 1.5585 - mae: 0.3292 - mse: 0.8842\n",
      "Epoch 00021: saving model to /kaggle/working\n",
      "2084656/2084656 [==============================] - 38s 18us/sample - loss: 1.5587 - mae: 0.3292 - mse: 0.8844 - val_loss: 1.4613 - val_mae: 0.2538 - val_mse: 0.8075\n",
      "Epoch 22/30\n",
      "2084000/2084656 [============================>.] - ETA: 0s - loss: 1.5231 - mae: 0.3297 - mse: 0.8880\n",
      "Epoch 00022: saving model to /kaggle/working\n",
      "2084656/2084656 [==============================] - 39s 18us/sample - loss: 1.5230 - mae: 0.3297 - mse: 0.8879 - val_loss: 1.4240 - val_mae: 0.2535 - val_mse: 0.8074\n",
      "Epoch 23/30\n",
      " 698000/2084656 [=========>....................] - ETA: 24s - loss: 1.5031 - mae: 0.3309 - mse: 0.8925"
     ]
    }
   ],
   "source": [
    "checkpoint_path = os.getcwd()\n",
    "checkpoint_dir = os.path.dirname(checkpoint_path)\n",
    "\n",
    "# Create a callback that saves the model's weights\n",
    "# not particularly useful in the Kaggle Notebook environment \n",
    "# but can be really useful for training in other environments\n",
    "checkpoint = tf.keras.callbacks.ModelCheckpoint(filepath=checkpoint_path,\n",
    "                                                 save_weights_only=True,\n",
    "                                                 verbose=1)\n",
    "\n",
    "# create an early stopping callback \n",
    "# will stop training if the validation MSE hasn't improved in (patience) epochs\n",
    "early_stop = keras.callbacks.EarlyStopping(monitor='val_loss', patience=5)\n",
    "\n",
    "# train the model\n",
    "history = model.fit(X_train, y_train,\n",
    "                    batch_size=1000,\n",
    "                    epochs=30, \n",
    "                    validation_data =(X_val, y_val),\n",
    "                    callbacks=[checkpoint, early_stop],\n",
    "                    verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loss</th>\n",
       "      <th>mae</th>\n",
       "      <th>mse</th>\n",
       "      <th>val_loss</th>\n",
       "      <th>val_mae</th>\n",
       "      <th>val_mse</th>\n",
       "      <th>epoch</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6.4637</td>\n",
       "      <td>0.3560</td>\n",
       "      <td>1.1491</td>\n",
       "      <td>5.2589</td>\n",
       "      <td>0.2846</td>\n",
       "      <td>0.8577</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.8441</td>\n",
       "      <td>0.3584</td>\n",
       "      <td>1.0157</td>\n",
       "      <td>4.2079</td>\n",
       "      <td>0.2849</td>\n",
       "      <td>0.8419</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.0348</td>\n",
       "      <td>0.3550</td>\n",
       "      <td>0.9839</td>\n",
       "      <td>3.6229</td>\n",
       "      <td>0.2744</td>\n",
       "      <td>0.8385</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.5521</td>\n",
       "      <td>0.3516</td>\n",
       "      <td>0.9664</td>\n",
       "      <td>3.2425</td>\n",
       "      <td>0.2670</td>\n",
       "      <td>0.8320</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.2288</td>\n",
       "      <td>0.3470</td>\n",
       "      <td>0.9556</td>\n",
       "      <td>2.9769</td>\n",
       "      <td>0.2667</td>\n",
       "      <td>0.8275</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2.9846</td>\n",
       "      <td>0.3437</td>\n",
       "      <td>0.9384</td>\n",
       "      <td>2.7750</td>\n",
       "      <td>0.2641</td>\n",
       "      <td>0.8233</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2.8085</td>\n",
       "      <td>0.3420</td>\n",
       "      <td>0.9371</td>\n",
       "      <td>2.6163</td>\n",
       "      <td>0.2665</td>\n",
       "      <td>0.8217</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2.6496</td>\n",
       "      <td>0.3404</td>\n",
       "      <td>0.9271</td>\n",
       "      <td>2.4717</td>\n",
       "      <td>0.2647</td>\n",
       "      <td>0.8196</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2.5032</td>\n",
       "      <td>0.3386</td>\n",
       "      <td>0.9194</td>\n",
       "      <td>2.3400</td>\n",
       "      <td>0.2592</td>\n",
       "      <td>0.8222</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2.3754</td>\n",
       "      <td>0.3382</td>\n",
       "      <td>0.9165</td>\n",
       "      <td>2.2187</td>\n",
       "      <td>0.2579</td>\n",
       "      <td>0.8162</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2.2577</td>\n",
       "      <td>0.3358</td>\n",
       "      <td>0.9098</td>\n",
       "      <td>2.1168</td>\n",
       "      <td>0.2557</td>\n",
       "      <td>0.8217</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2.1566</td>\n",
       "      <td>0.3356</td>\n",
       "      <td>0.9099</td>\n",
       "      <td>2.0154</td>\n",
       "      <td>0.2568</td>\n",
       "      <td>0.8159</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2.0594</td>\n",
       "      <td>0.3344</td>\n",
       "      <td>0.9042</td>\n",
       "      <td>1.9260</td>\n",
       "      <td>0.2564</td>\n",
       "      <td>0.8129</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1.9755</td>\n",
       "      <td>0.3337</td>\n",
       "      <td>0.9027</td>\n",
       "      <td>1.8440</td>\n",
       "      <td>0.2569</td>\n",
       "      <td>0.8097</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1.8973</td>\n",
       "      <td>0.3331</td>\n",
       "      <td>0.8992</td>\n",
       "      <td>1.7756</td>\n",
       "      <td>0.2559</td>\n",
       "      <td>0.8124</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>1.8285</td>\n",
       "      <td>0.3322</td>\n",
       "      <td>0.8975</td>\n",
       "      <td>1.7120</td>\n",
       "      <td>0.2549</td>\n",
       "      <td>0.8123</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>1.7675</td>\n",
       "      <td>0.3320</td>\n",
       "      <td>0.8970</td>\n",
       "      <td>1.6537</td>\n",
       "      <td>0.2514</td>\n",
       "      <td>0.8115</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>1.7057</td>\n",
       "      <td>0.3307</td>\n",
       "      <td>0.8904</td>\n",
       "      <td>1.6000</td>\n",
       "      <td>0.2513</td>\n",
       "      <td>0.8113</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>1.6560</td>\n",
       "      <td>0.3302</td>\n",
       "      <td>0.8921</td>\n",
       "      <td>1.5495</td>\n",
       "      <td>0.2556</td>\n",
       "      <td>0.8099</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>1.6096</td>\n",
       "      <td>0.3308</td>\n",
       "      <td>0.8924</td>\n",
       "      <td>1.5006</td>\n",
       "      <td>0.2548</td>\n",
       "      <td>0.8055</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>1.5587</td>\n",
       "      <td>0.3292</td>\n",
       "      <td>0.8844</td>\n",
       "      <td>1.4613</td>\n",
       "      <td>0.2538</td>\n",
       "      <td>0.8075</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>1.5230</td>\n",
       "      <td>0.3297</td>\n",
       "      <td>0.8879</td>\n",
       "      <td>1.4240</td>\n",
       "      <td>0.2535</td>\n",
       "      <td>0.8074</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>1.4868</td>\n",
       "      <td>0.3295</td>\n",
       "      <td>0.8879</td>\n",
       "      <td>1.3937</td>\n",
       "      <td>0.2533</td>\n",
       "      <td>0.8120</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>1.4546</td>\n",
       "      <td>0.3292</td>\n",
       "      <td>0.8883</td>\n",
       "      <td>1.3570</td>\n",
       "      <td>0.2555</td>\n",
       "      <td>0.8059</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>1.4172</td>\n",
       "      <td>0.3286</td>\n",
       "      <td>0.8809</td>\n",
       "      <td>1.3282</td>\n",
       "      <td>0.2529</td>\n",
       "      <td>0.8065</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>1.3895</td>\n",
       "      <td>0.3284</td>\n",
       "      <td>0.8820</td>\n",
       "      <td>1.3019</td>\n",
       "      <td>0.2522</td>\n",
       "      <td>0.8081</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>1.3650</td>\n",
       "      <td>0.3286</td>\n",
       "      <td>0.8842</td>\n",
       "      <td>1.2725</td>\n",
       "      <td>0.2556</td>\n",
       "      <td>0.8041</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>1.3374</td>\n",
       "      <td>0.3281</td>\n",
       "      <td>0.8806</td>\n",
       "      <td>1.2497</td>\n",
       "      <td>0.2589</td>\n",
       "      <td>0.8040</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>1.3114</td>\n",
       "      <td>0.3275</td>\n",
       "      <td>0.8767</td>\n",
       "      <td>1.2248</td>\n",
       "      <td>0.2564</td>\n",
       "      <td>0.8007</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>1.2923</td>\n",
       "      <td>0.3277</td>\n",
       "      <td>0.8780</td>\n",
       "      <td>1.2058</td>\n",
       "      <td>0.2547</td>\n",
       "      <td>0.8009</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     loss    mae    mse  val_loss  val_mae  val_mse  epoch\n",
       "0  6.4637 0.3560 1.1491    5.2589   0.2846   0.8577      0\n",
       "1  4.8441 0.3584 1.0157    4.2079   0.2849   0.8419      1\n",
       "2  4.0348 0.3550 0.9839    3.6229   0.2744   0.8385      2\n",
       "3  3.5521 0.3516 0.9664    3.2425   0.2670   0.8320      3\n",
       "4  3.2288 0.3470 0.9556    2.9769   0.2667   0.8275      4\n",
       "5  2.9846 0.3437 0.9384    2.7750   0.2641   0.8233      5\n",
       "6  2.8085 0.3420 0.9371    2.6163   0.2665   0.8217      6\n",
       "7  2.6496 0.3404 0.9271    2.4717   0.2647   0.8196      7\n",
       "8  2.5032 0.3386 0.9194    2.3400   0.2592   0.8222      8\n",
       "9  2.3754 0.3382 0.9165    2.2187   0.2579   0.8162      9\n",
       "10 2.2577 0.3358 0.9098    2.1168   0.2557   0.8217     10\n",
       "11 2.1566 0.3356 0.9099    2.0154   0.2568   0.8159     11\n",
       "12 2.0594 0.3344 0.9042    1.9260   0.2564   0.8129     12\n",
       "13 1.9755 0.3337 0.9027    1.8440   0.2569   0.8097     13\n",
       "14 1.8973 0.3331 0.8992    1.7756   0.2559   0.8124     14\n",
       "15 1.8285 0.3322 0.8975    1.7120   0.2549   0.8123     15\n",
       "16 1.7675 0.3320 0.8970    1.6537   0.2514   0.8115     16\n",
       "17 1.7057 0.3307 0.8904    1.6000   0.2513   0.8113     17\n",
       "18 1.6560 0.3302 0.8921    1.5495   0.2556   0.8099     18\n",
       "19 1.6096 0.3308 0.8924    1.5006   0.2548   0.8055     19\n",
       "20 1.5587 0.3292 0.8844    1.4613   0.2538   0.8075     20\n",
       "21 1.5230 0.3297 0.8879    1.4240   0.2535   0.8074     21\n",
       "22 1.4868 0.3295 0.8879    1.3937   0.2533   0.8120     22\n",
       "23 1.4546 0.3292 0.8883    1.3570   0.2555   0.8059     23\n",
       "24 1.4172 0.3286 0.8809    1.3282   0.2529   0.8065     24\n",
       "25 1.3895 0.3284 0.8820    1.3019   0.2522   0.8081     25\n",
       "26 1.3650 0.3286 0.8842    1.2725   0.2556   0.8041     26\n",
       "27 1.3374 0.3281 0.8806    1.2497   0.2589   0.8040     27\n",
       "28 1.3114 0.3275 0.8767    1.2248   0.2564   0.8007     28\n",
       "29 1.2923 0.3277 0.8780    1.2058   0.2547   0.8009     29"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hist = pd.DataFrame(history.history)\n",
    "hist['epoch'] = history.epoch\n",
    "hist.to_csv('model_history.csv', index=False)\n",
    "hist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "def plot_history(hist):\n",
    "    plt.figure()\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Mean Abs Error')\n",
    "    plt.plot(hist['epoch'], hist['mae'],\n",
    "           label='Train Error')\n",
    "    plt.plot(hist['epoch'], hist['val_mae'],\n",
    "           label='Val Error')  \n",
    "    plt.legend()\n",
    "\n",
    "    plt.figure()\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Mean Square Error')\n",
    "    plt.plot(hist['epoch'], hist['mse'],\n",
    "           label='Train Error')\n",
    "    plt.plot(hist['epoch'], hist['val_mse'],\n",
    "           label='Val Error')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "plot_history(hist.iloc[5:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2084656/2084656 [==============================] - 149s 71us/sample - loss: 1.2457 - mae: 0.3134 - mse: 0.8408\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.2456912143221508, 0.3134427, 0.84081984]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict(X_test).clip(0, 20)\n",
    "submission = pd.DataFrame({\n",
    "    \"ID\": test_data.index,\n",
    "    'item_cnt_month': predictions.flatten()\n",
    "})\n",
    "submission.to_csv('model_output.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "and there we have it! A functioning neural network with categorical feature embeddings...."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Results and Final Thoughts\n",
    "\n",
    "The model presented is just a basic example - the dataset used and the model's structure / parameterization / number of training epochs have been chosen for ease of explanation and to achieve some resonably quick results. As such, don't expect mind-blowing predictions in its current state. I would encourage anyone interested to fork this notebook, upload your own prepared dataset and have a play around. As is always the case with neural networks, there are a huge number of possible architectures and parameters to play around with. Possible interesting avenues include:\n",
    "\n",
    "* adding / removing / widening / shortening  layers in the network\n",
    "* adjusting the regularization layers / parameters (dropout / l2)\n",
    "* adding new regularization parameters\n",
    "* changing activation functions\n",
    "* changing the gradient descent optimizer\n",
    "* adjusting the learning rate and no of epochs\n",
    "* etc, etc.....\n",
    "\n",
    "With some tinkering, you'll find that the networks performance can quickly approach that of the aforementioned popular models. Neural networks like this also offer a huge amount of flexibility which can offer some really promising avenues for improving your scores. \n",
    "\n",
    "<b>Note: you can dramatically improve the training time of the model by increasing the batch size and utilizing a GPU session!</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "_cell_guid": "",
    "_uuid": ""
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "item_categories = pd.read_csv(\"../input/competitive-data-science-predict-future-sales/item_categories.csv\")\n",
    "items = pd.read_csv(\"../input/competitive-data-science-predict-future-sales/items.csv\")\n",
    "shops = pd.read_csv(\"../input/competitive-data-science-predict-future-sales/shops.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
